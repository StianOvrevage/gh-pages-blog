<!doctype html><html lang=en-us dir=ltr><head><meta charset=utf-8><meta name=viewport content='width=device-width,initial-scale=1'><meta name=description content="Quite often people ask me what I actually do. I have a hard time giving a short answer. Even to colleagues and friends in the industry.\nHere I will try to show and tell how I spent an evening digging around in a system I helped build for a client.\n"><title>A side quest in API development, observability, Kubernetes and cloud with a hint of database</title>
<link rel=canonical href=https://demo.stack.jimmycai.com/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/><link rel=stylesheet href=/scss/style.min.663803bebe609202d5b39d848f2d7c2dc8b598a2d879efa079fa88893d29c49c.css><meta property='og:title' content="A side quest in API development, observability, Kubernetes and cloud with a hint of database"><meta property='og:description' content="Quite often people ask me what I actually do. I have a hard time giving a short answer. Even to colleagues and friends in the industry.\nHere I will try to show and tell how I spent an evening digging around in a system I helped build for a client.\n"><meta property='og:url' content='https://demo.stack.jimmycai.com/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/'><meta property='og:site_name' content='blog.stian.omg.lol'><meta property='og:type' content='article'><meta property='article:section' content='Post'><meta property='article:tag' content='kubernetes'><meta property='article:tag' content='databases'><meta property='article:tag' content='observability'><meta property='article:published_time' content='2021-03-06T00:00:00+00:00'><meta property='article:modified_time' content='2021-03-06T00:00:00+00:00'><meta name=twitter:title content="A side quest in API development, observability, Kubernetes and cloud with a hint of database"><meta name=twitter:description content="Quite often people ask me what I actually do. I have a hard time giving a short answer. Even to colleagues and friends in the industry.\nHere I will try to show and tell how I spent an evening digging around in a system I helped build for a client.\n"><link rel="shortcut icon" href=/favicon.png></head><body class=article-page><script>(function(){const e="StackColorScheme";localStorage.getItem(e)||localStorage.setItem(e,"auto")})()</script><script>(function(){const t="StackColorScheme",e=localStorage.getItem(t),n=window.matchMedia("(prefers-color-scheme: dark)").matches===!0;e=="dark"||e==="auto"&&n?document.documentElement.dataset.scheme="dark":document.documentElement.dataset.scheme="light"})()</script><div class="container main-container flex on-phone--column extended"><aside class="sidebar left-sidebar sticky"><button class="hamburger hamburger--spin" type=button id=toggle-menu aria-label="Toggle Menu">
<span class=hamburger-box><span class=hamburger-inner></span></span></button><header><figure class=site-avatar><a href=/><img src=/img/profile-picture_hu6892409687065925510.jpg width=300 height=300 class=site-logo loading=lazy alt=Avatar>
</a><span class=emoji>ü§∑‚Äç‚ôÇÔ∏è</span></figure><div class=site-meta><h1 class=site-name><a href=/>blog.stian.omg.lol</a></h1><h2 class=site-description>Technology. Aviation. Philosophy.</h2></div></header><ol class=menu-social><li><a href=https://github.com/StianOvrevage target=_blank title=GitHub rel=me><svg class="icon icon-tabler icon-tabler-brand-github" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z" fill="none"/><path d="M9 19c-4.3 1.4-4.3-2.5-6-3m12 5v-3.5c0-1 .1-1.4-.5-2 2.8-.3 5.5-1.4 5.5-6a4.6 4.6.0 00-1.3-3.2 4.2 4.2.0 00-.1-3.2s-1.1-.3-3.5 1.3a12.3 12.3.0 00-6.2.0C6.5 2.8 5.4 3.1 5.4 3.1a4.2 4.2.0 00-.1 3.2A4.6 4.6.0 004 9.5c0 4.6 2.7 5.7 5.5 6-.6.6-.6 1.2-.5 2V21"/></svg></a></li></ol><ol class=menu id=main-menu><li><a href=/><svg class="icon icon-tabler icon-tabler-home" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><polyline points="5 12 3 12 12 3 21 12 19 12"/><path d="M5 12v7a2 2 0 002 2h10a2 2 0 002-2v-7"/><path d="M9 21v-6a2 2 0 012-2h2a2 2 0 012 2v6"/></svg>
<span>Home</span></a></li><li><a href=/archives/><svg class="icon icon-tabler icon-tabler-archive" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><rect x="3" y="4" width="18" height="4" rx="2"/><path d="M5 8v10a2 2 0 002 2h10a2 2 0 002-2V8"/><line x1="10" y1="12" x2="14" y2="12"/></svg>
<span>Archives</span></a></li><li><a href=/search/><svg class="icon icon-tabler icon-tabler-search" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="10" cy="10" r="7"/><line x1="21" y1="21" x2="15" y2="15"/></svg>
<span>Search</span></a></li><li><a href=/links/><svg class="icon icon-tabler icon-tabler-link" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M10 14a3.5 3.5.0 005 0l4-4a3.5 3.5.0 00-5-5l-.5.5"/><path d="M14 10a3.5 3.5.0 00-5 0l-4 4a3.5 3.5.0 005 5l.5-.5"/></svg>
<span>Links</span></a></li><li class=menu-bottom-section><ol class=menu><li id=dark-mode-toggle><svg class="icon icon-tabler icon-tabler-toggle-left" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="8" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<svg class="icon icon-tabler icon-tabler-toggle-right" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="16" cy="12" r="2"/><rect x="2" y="6" width="20" height="12" rx="6"/></svg>
<span>Dark Mode</span></li></ol></li></ol></aside><aside class="sidebar right-sidebar sticky"><section class="widget archives"><div class=widget-icon><svg class="icon icon-tabler icon-tabler-hash" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><line x1="5" y1="9" x2="19" y2="9"/><line x1="5" y1="15" x2="19" y2="15"/><line x1="11" y1="4" x2="7" y2="20"/><line x1="17" y1="4" x2="13" y2="20"/></svg></div><h2 class="widget-title section-title">Table of contents</h2><div class=widget--toc><nav id=TableOfContents><ol><li><a href=#fixing-the-initial-problem>Fixing the (initial) problem</a></li><li><a href=#verifying-the-initial-fix>Verifying the (initial) fix</a><ol><li><a href=#baseline-simple-request---http1-1-connections-20000-requests>Baseline simple request - HTTP1 1 connections, 20000 requests</a></li><li><a href=#baseline-complex-request---http1-1-connections-20000-requests>Baseline complex request - HTTP1 1 connections, 20000 requests</a></li></ol></li><li><a href=#verifying-the-fix-for-assumed-workload>Verifying the fix for assumed workload</a><ol><li><a href=#complex-request---http1-6-connections-500-requests>Complex request - HTTP1 6 connections, 500 requests</a></li><li><a href=#complex-request---http2-500-connections-500-requests>Complex request - HTTP2 500 &ldquo;connections&rdquo;, 500 requests</a></li></ol></li></ol></nav></div></section></aside><main class="main full-width"><article class=main-article><header class=article-header><div class=article-details><header class=article-category><a href=/categories/technology/ style=background-color:#2a9d8f;color:#fff>Technology</a></header><div class=article-title-wrapper><h2 class=article-title><a href=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/>A side quest in API development, observability, Kubernetes and cloud with a hint of database</a></h2></div><footer class=article-time><div><svg class="icon icon-tabler icon-tabler-calendar-time" width="56" height="56" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><path d="M11.795 21H5a2 2 0 01-2-2V7a2 2 0 012-2h12a2 2 0 012 2v4"/><circle cx="18" cy="18" r="4"/><path d="M15 3v4"/><path d="M7 3v4"/><path d="M3 11h16"/><path d="M18 16.496V18l1 1"/></svg>
<time class=article-time--published>Mar 06, 2021</time></div><div><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<time class=article-time--reading>11 minute read</time></div></footer></div></header><section class=article-content><p>Quite often people ask me what I actually do. I have a hard time giving a short answer. Even to colleagues and friends in the industry.</p><p>Here I will try to show and tell how I spent an evening digging around in a system I helped build for a client.</p><br><hr><br><p><strong>Table of contents</strong></p><ul><li><a class=link href=#Background>Background</a></li><li><a class=link href=#TheProblem>The (initial) problem</a><ul><li><a class=link href=#FurtherReading>Fixing the (initial) problem</a></li><li><a class=link href=#FurtherReading>Verifying the (initial) fix</a><ul><li><a class=link href=#FurtherReading>Baseline simple request - HTTP1 1 connections, 20000 requests</a></li><li><a class=link href=#FurtherReading>Baseline complex request - HTTP1 1 connections, 20000 requests</a></li></ul></li><li><a class=link href=#FurtherReading>Verifying the fix for assumed workload</a><ul><li><a class=link href=#FurtherReading>Complex request - HTTP1 6 connections, 500 requests</a></li><li><a class=link href=#FurtherReading>Complex request - HTTP2 500 &ldquo;connections&rdquo;, 500 requests</a></li></ul></li></ul></li><li><a class=link href=#FurtherReading>Side quest: Database optimizations</a></li><li><a class=link href=#FurtherReading>Determining the next bottleneck</a></li><li><a class=link href=#FurtherReading>Side quest: Cluster resources and burstable VMs</a></li><li><a class=link href=#Conclusion>Conclusion</a></li></ul><p><a id=Background></a></p><h1 id=background>Background</h1><p>I&rsquo;m a consultant doing development, DevOps and cloud infrastructure.</p><p>For this specific client I mainly develop APIs using Golang to support new products and features as well as various exporting, importing and processing of data in the background.</p><p>I&rsquo;m also the &ldquo;ops&rdquo; guy handling everything in AWS, setting up and maintaing databases, making sure the &ldquo;DevOps&rdquo; works and the frontend and analytics people can do their work with little friction.
99% of the time things work just fine. No data is lost. The systems very rarely have unforeseen downtime and the users can access the data they want with acceptable latency rarely exceeding 500ms.</p><p>A couple of times a year I assess the status of the architecture and set up new environments from scratch and update any documentation that has drifted. This is also a good time to do changes and add or remove constraints in anticipation of future business needs.</p><p>In short, the current tech stack that has evolved over a couple of years is:</p><ul><li>Everything hosted on Amazon Web Services (AWS).</li><li>AWS managed Elastic Kubernetes Service (EKS) currently on K8s 1.18.</li><li>GitHub Actions for building Docker images for frontends, backends and other systems.</li><li>AWS Elastic Container Registry for storing Docker images.</li><li>Deployment of each system defined as a Helm chart alongside source code.</li><li>Actual environment configuration (Helm values) stored in repo along source code. Updated by GitHub Actions.</li><li>ArgoCD in cluster to manage status of all environments and deployments. Development environments usually automatically deployed on change. Push a button to deploy to Production.</li><li>Prometheus for storing metrics from the cluster and nodes itself as well as custom metrics for our own systems.</li><li>Loki for storing logs. Makes it easier to retrieve logs from past Pods and aggregate across multiple Pods.</li><li>Elastic APM server for tracing.</li><li>Pyroscope for live CPU profiling/tracing of Go applications.</li><li>Betteruptime.com for tracking uptime and hosting status pages.</li></ul><p>I might write up a longer post about the details if anyone is interested.</p><p><a id=TheProblem></a></p><h1 id=the-initial-problem>The (initial) problem</h1><p>A week ago I upgraded our API from version 1, that was deployed in January, to version 2 with new features and better architecture.</p><p>One of the endpoints of the API returns an analysis of an object we track. I have previously reduced the amount of database queries by 90% but it still requires about 50 database calls from three different databases.
Getting and analyzing the data usually completes in about 3-400 milliseconds returning an 11.000 line JSON.</p><p>It&rsquo;s also possible to just call <code>/objects/analysis</code> to get the analysis for all the 500 objects we are tracking. It takes 20 seconds but is meant for exports to other processes and not interactive use, so not a problem.</p><p>Since the product is under very active development the frontend guys just download the whole analysis for an object to show certain relevant information to users. It&rsquo;s too early to decide on which information is needed more often and how to optimize for that. Not a problem.</p><p>So we need an overview of some fields from multiple objects in a dashboard / list. We can easily pull analysis from 20 objects without any noticable delay.</p><p>But what if we just want to show more, 50? 200? 500? The frontend already have the IDs for all the objects and fetches them from <code>/objects/id/analysis</code>. So they loop over the IDs and fire of requests simultaneously.</p><p>Analyzing the network waterfall in Chrome DevTools indicated that the requests now took 20-30 seconds to complete! But looking closer most of the time they were actually queued up in the browser. This is because
Chrome only allows 6 concurrent TCP connection to the same origin when using HTTP1 (<a class=link href=https://developers.google.com/web/tools/chrome-devtools/network/understanding-resource-timing%29 target=_blank rel=noopener>https://developers.google.com/web/tools/chrome-devtools/network/understanding-resource-timing)</a>.</p><p><a id=TheProblem></a></p><h2 id=fixing-the-initial-problem>Fixing the (initial) problem</h2><p>HTTP2 should fix this problem easily. By default HTTP2 is disabled in nginx-ingress. I add a couple of lines enabling it and update the Helm deployment of the ingress controller.</p><p><a id=TheProblem></a></p><h2 id=verifying-the-initial-fix>Verifying the (initial) fix</h2><p>Some common development tools doesn&rsquo;t support HTTP2, such as Postman. So I found <code>h2load</code> which can both help me verify HTTP2 is working and I also get to measure the improvement, nice!</p><blockquote><p>Note that I&rsquo;m not using the analysis endpoint since I want to measure the change from HTTP1 to HTTP2 and it will become apparent later that there are other bottlenecks preventing us from a linear performance increase when just changing from HTTP1 to HTTP2.</p></blockquote><blockquote><p>Also note that this is somewhat naive since it requests the same URL over and over which can give false results due to any caching. But fortunately we don&rsquo;t do any caching yet.</p></blockquote><p><a id=TheProblem></a></p><h3 id=baseline-simple-request---http1-1-connections-20000-requests>Baseline simple request - HTTP1 1 connections, 20000 requests</h3><p>Using 1 concurrent streams, 1 client and HTTP1 I get an estimate of performance pre-http2:</p><pre><code>h2load --h1 --requests=20000 --clients=1 --max-concurrent-streams=1 https://api.x.com/api/v1/objects/1
</code></pre><p>The results are as expected:</p><pre><code>finished in 1138.99s, 17.56 req/s, 18.41KB/s
requests: 20000 total, 20000 started, 20000 done, 19995 succeeded, 5 failed, 0 errored, 0 timeout
</code></pre><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-apm.png width=1816 height=705 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-apm_hu17076544040877865054.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-apm_hu9690961613720477067.png 1024w" loading=lazy alt="Overview from Elastic APM. Duration is very acceptable at around 20ms. No errors. And about 25% of the time spent doing database queries." class=gallery-image data-flex-grow=257 data-flex-basis=618px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-cpu.png width=1034 height=314 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-cpu_hu2013984859425220242.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-cpu_hu13236457479005124721.png 1024w" loading=lazy alt="Container CPU usage. Nothing special." class=gallery-image data-flex-grow=329 data-flex-basis=790px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-db-latency.png width=861 height=356 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-db-latency_hu1867474644236441644.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-db-latency_hu15523458481306920119.png 1024w" loading=lazy alt="Database query latency. The vast majority under 5ms. Acceptable." class=gallery-image data-flex-grow=241 data-flex-basis=580px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-db-queries.png width=780 height=348 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-db-queries_hu17361066750422420350.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-db-queries_hu10420784785634132053.png 1024w" loading=lazy alt="Number of DB queries per second." class=gallery-image data-flex-grow=224 data-flex-basis=537px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-http-latency.png width=863 height=316 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-http-latency_hu6805455395055610702.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-http-latency_hu3298924550317512719.png 1024w" loading=lazy alt="HTTP response latency." class=gallery-image data-flex-grow=273 data-flex-basis=655px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-http-requests.png width=778 height=217 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-http-requests_hu5945712598158928612.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/0-baseline-http1-1-concurrent-http-requests_hu419352892190289981.png 1024w" loading=lazy alt="Number of HTTP requests per second. Unsurprisingly the number of database queries are identical to the number of HTTP requests. Latency of HTTP requests also tracks the latency of the (single) database query." class=gallery-image data-flex-grow=358 data-flex-basis=860px></p><p>For http2 we set max concurrent streams to the same as number of requests:</p><pre><code>h2load --requests=200 --clients=1 --max-concurrent-streams=200 https://api.x.com/api/v1/objects/1
</code></pre><p>Which results in almost half the latency:</p><pre><code>finished in 1.23s, 162.65 req/s, 158.06KB/s
requests: 200 total, 200 started, 200 done, 200 succeeded, 0 failed, 0 errored, 0 timeout
</code></pre><p>So HTTP2 is working and providing significant latency improvements. Success!</p><p><a id=TheProblem></a></p><h3 id=baseline-complex-request---http1-1-connections-20000-requests>Baseline complex request - HTTP1 1 connections, 20000 requests</h3><p>We start by establishing a baseline with 1 connection querying over and over.</p><pre><code>h2load --h1 --requests=20000 --clients=1 --max-concurrent-streams=1
</code></pre><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-apm.png width=2087 height=707 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-apm_hu13565166093859492250.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-apm_hu14225806095910349646.png 1024w" loading=lazy alt="Latency increases as much more computation is done and data is returned. But the latency is consistent which is good. We also see that the database is becomming the bottleneck for where most time is spent." class=gallery-image data-flex-grow=295 data-flex-basis=708px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-cpu.png width=1200 height=308 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-cpu_hu4067009256511003722.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-cpu_hu17950687200232907900.png 1024w" loading=lazy alt="CPU usage increased to 15%. Lower increase than expected considering the complexity involved in serving the requests." class=gallery-image data-flex-grow=389 data-flex-basis=935px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-db-latency.png width=985 height=344 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-db-latency_hu7089278039337102831.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-db-latency_hu17575998733902921949.png 1024w" loading=lazy alt="Database query latency still mostly under 5ms." class=gallery-image data-flex-grow=286 data-flex-basis=687px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-db-queries.png width=894 height=351 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-db-queries_hu6509951597429203579.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-db-queries_hu14549008744426915283.png 1024w" loading=lazy alt="Number of database queries increases by a factor of 10 compared to HTTP requests." class=gallery-image data-flex-grow=254 data-flex-basis=611px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-http-latency.png width=987 height=313 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-http-latency_hu565398038381364000.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-http-latency_hu7243746795286387547.png 1024w" loading=lazy alt="HTTP latency." class=gallery-image data-flex-grow=315 data-flex-basis=756px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-http-requests.png width=895 height=219 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-http-requests_hu9040739607883373017.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/1-baseline-http1-1-concurrent-analysis-http-requests_hu3790465645525383070.png 1024w" loading=lazy alt="HTTP requests per second." class=gallery-image data-flex-grow=408 data-flex-basis=980px></p><p><a id=TheProblem></a></p><h2 id=verifying-the-fix-for-assumed-workload>Verifying the fix for assumed workload</h2><p>So we verified that HTTP2 gives us a performance boost. But what happens when we fire away 500 requests to the much heavier <code>/analysis</code> endpoint?</p><blockquote><p>These graphs are not as pretty since the ones above. This is mainly due to the sampling interval of the metrics and that we need several datapoints to accurately determine the rate() of a counter.</p></blockquote><p><a id=TheProblem></a></p><h3 id=complex-request---http1-6-connections-500-requests>Complex request - HTTP1 6 connections, 500 requests</h3><pre><code>finished in 32.25s, 14.88 req/s, 2.29MB/s
requests: 500 total, 500 started, 500 done, 500 succeeded, 0 failed, 0 errored, 0 timeout
</code></pre><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-apm.png width=1484 height=705 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-apm_hu2573287072721533229.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-apm_hu10620414983979950514.png 1024w" loading=lazy alt=2-burst-http1-6-concurrent-analysis-apm class=gallery-image data-flex-grow=210 data-flex-basis=505px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-cpu.png width=847 height=299 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-cpu_hu1135877464954207689.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-cpu_hu17008451797633252465.png 1024w" loading=lazy alt=2-burst-http1-6-concurrent-analysis-cpu class=gallery-image data-flex-grow=283 data-flex-basis=679px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-db-latency.png width=706 height=359 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-db-latency_hu9358974391483687749.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-db-latency_hu16352819740947538611.png 1024w" loading=lazy alt=2-burst-http1-6-concurrent-analysis-db-latency class=gallery-image data-flex-grow=196 data-flex-basis=471px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-db-queries.png width=637 height=352 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-db-queries_hu17797633323803646239.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-db-queries_hu2207066698060964218.png 1024w" loading=lazy alt=2-burst-http1-6-concurrent-analysis-db-queries class=gallery-image data-flex-grow=180 data-flex-basis=434px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-http-latency.png width=700 height=321 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-http-latency_hu13253021454442065078.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-http-latency_hu13649080090034874975.png 1024w" loading=lazy alt=2-burst-http1-6-concurrent-analysis-http-latency class=gallery-image data-flex-grow=218 data-flex-basis=523px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-http-requests.png width=638 height=213 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-http-requests_hu12544065771888019895.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/2-burst-http1-6-concurrent-analysis-http-requests_hu1798439057131787658.png 1024w" loading=lazy alt=2-burst-http1-6-concurrent-analysis-http-requests class=gallery-image data-flex-grow=299 data-flex-basis=718px></p><p>In summary it so far seems to scale linearly with load. Most of the time is spent fetching data from the database. Still very predictable low latency on database queries and the resulting HTTP response.</p><p><a id=TheProblem></a></p><h3 id=complex-request---http2-500-connections-500-requests>Complex request - HTTP2 500 &ldquo;connections&rdquo;, 500 requests</h3><p><em>So now we unleash the beast. Firing all 500 requests at the same time.</em></p><pre><code>finished in 16.66s, 30.02 req/s, 3.55MB/s
requests: 500 total, 500 started, 500 done, 500 succeeded, 0 failed, 0 errored, 0 timeout
</code></pre><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-cpu.png width=939 height=307 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-cpu_hu5828488102210360607.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-cpu_hu3343570902582545481.png 1024w" loading=lazy alt="CPU on API still doing good. A slight hint of CPU throttling due to CFS, which is used when you set CPU limits in Kubernetes." class=gallery-image data-flex-grow=305 data-flex-basis=734px></p><blockquote><p>Important about Kubernetes and CPU limits<br>Even with CPU limits set to 1 (100% of one CPU), your container can still be throttled at much lower CPU usage. Check out <a class=link href=https://medium.com/omio-engineering/cpu-limits-and-aggressive-throttling-in-kubernetes-c5b20bd8a718 target=_blank rel=noopener>this article</a> for more information.</p></blockquote><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-db-latency.png width=782 height=346 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-db-latency_hu16596262103242219393.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-db-latency_hu6743393326456624241.png 1024w" loading=lazy alt="Whopsie. The average database query latency has increased drastically, and we have a long tail of very slow queries. Looks like we are starting to see signs of bottlenecks on the database. This might also be affected by our maximum of 60 concurrent connections to the database, resulting in queries having to wait their turn before executing." class=gallery-image data-flex-grow=226 data-flex-basis=542px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-db-queries.png width=705 height=346 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-db-queries_hu17270843372303526721.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-db-queries_hu14745640312772792195.png 1024w" loading=lazy alt="Its hard to judge the peak rate of database queries due to limited sampling of the metrics." class=gallery-image data-flex-grow=203 data-flex-basis=489px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-http-latency.png width=783 height=309 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-http-latency_hu9429010041105922198.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-http-latency_hu14677623071583589615.png 1024w" loading=lazy alt="Now individual HTTP requests are much slower due to waiting for the database." class=gallery-image data-flex-grow=253 data-flex-basis=608px></p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-apm-trace.png width=1150 height=1192 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-apm-trace_hu12116834356231894546.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/3-burst-http2-500-concurrent-analysis-apm-trace_hu17401424198592652531.png 1024w" loading=lazy alt="Here is just a random trace from Elastic APM to see if the increased database latency is concentrated to specific queries or tables or just general saturation. Indeed there is a single query responsible for half the time taken for the entire query! We better get back to that in a bit and dig further." class=gallery-image data-flex-grow=96 data-flex-basis=231px></p><p>In an ideal world all 500 requests should start and complete in 2-300ms regardless. Since that is not happening it&rsquo;s an indication that we are now hitting some other bottleneck.</p><p>Looking at the graphs it seems we are starting to saturate the database. The latency for every request is now largely dependent on the slowest of the 10-12 database queries it depends on. And as we are stressing the database the probability of slow queries increase. The latency for the whole process of fetching 500 requests are again largely dependent on the slowest requests.</p><p>So this optimization gives on average better performance, but more variability of the individual requests, when the system is under heavy load.</p><p><a id=TheProblem></a></p><h1 id=side-quest-database-optimizations>Side quest: Database optimizations</h1><p>It seems we are saturating the database. Before throwing more money at the problem (by increasing database size) I like to know what the bottlenecks are. Looking at the traces from APM
I see one query that is consistently taking 10x longer than the rest. I also confirm this in the AWS RDS Performance Insights that show the top SQL queries by load.</p><p>When designing the database schema I came up with the idea of having immutability for certain data types. So instead of overwriting row with ID 1, we add a row with ID 1 Revision 2. Now we have the history of who did what to the data and can easily track changes and roll back if needed. The most common use case is just fetching the last revision. So for simplicity I created a PostgreSQL view that only shows the last revision. That way clients don&rsquo;t have to worry about the existense of revisions at all. That is now just an implementation detail.</p><p>When it comes to performance that turns out to be an important implementation detail. The view is using <code>SELECT DISTINCT ON (id) ... ORDER BY id, revision DESC</code>. However many of the queries to the view is ordering the returned data by time, and expect the data returned from database to already be ordered chronologically. Using <code>EXPLAIN ANALYZE</code> on the queries this always results in a full table scan instead of using indexes, and is what&rsquo;s causing this specific query to be slow. Without going into details it seems there is no simple and efficient way of having a view with the last revision and query that for a subset of rows ordered again by time.</p><p>For the forseable future this does not actually impact real world usage. It&rsquo;s only apparent under artificially large loads under the worst conditions. But now we know where we need to refactor things if performance actually becomes a problem.</p><p><a id=TheProblem></a></p><h1 id=determining-the-next-bottleneck>Determining the next bottleneck</h1><p>Whenever I fix one problem I like to know where, how and when the next problem or limit is likely to appear. When increasing the number of requests and streams I expected to see increasing latency. But instead I see errors appear like a cliff:</p><pre><code>finished in 27.33s, 36.59 req/s, 5.64MB/s
requests: 5000 total, 1002 started, 1002 done, 998 succeeded, 4002 failed, 4000 errored, 0 timeout
</code></pre><p>Consulting the logs for both the nginx load balancer and the API there are no records of failing requests. Since nginx does not pass the HTTP2 connection directly to the API, but instead &ldquo;unbundles&rdquo; them into HTTP1 requests I suspect there might be issues with connection limits or even available ports from nginx to the API. But maybe it&rsquo;s a configuration issue. By default nginx does <a class=link href=http://nginx.org/en/docs/http/ngx_http_upstream_module.html#server target=_blank rel=noopener>not limit the number of connections to a backend</a> (our API). . But, there is actually a <a class=link href=https://nginx.org/en/docs/http/ngx_http_v2_module.html#http2_max_requests target=_blank rel=noopener>default limit to the number of HTTP2 requests that can be served over a single connection</a> - And it happens to be 1000.</p><p>I leave it at that. It&rsquo;s very unlikely we&rsquo;ll be hitting these limits any time soon.</p><p><a id=TheProblem></a></p><h1 id=side-quest-cluster-resources-and-burstable-vms>Side quest: Cluster resources and burstable VMs</h1><p>When load testing the first time around sometimes Grafana would also become unresponsive. That&rsquo;s usually a bad sign. It might indicate that the underlying infrastructure is also reaching saturation. That is not good since it can impact what should be independent services.</p><p>Our Kubernetes cluster is composed of 2x t3a.medium on demand nodes and 2x t3a.medium spot nodes. These VM types are burstable. You can use 20% per vCPU sustained over time without problems. If you exceed those 20% you start consuming CPU credits faster than they are granted and once you run out of CPU credits processes will be forcibly throttled.</p><p>Of course Kubernetes does not know about this and expects 1 CPU to actually be 1 CPU. In addition Kubernetes will decide where to place workloads based on their stated resource requirements and limits, and not their actual resource usage.</p><p>When looking at the actual metrics two of our nodes are indeed out of CPU credits and being throttled. The sum of factors leading to this is:</p><ul><li>We have not yet set resource requests and limits making it harder for Kubernetes to intelligently place workloads</li><li>Using burstable nodes having some additional constraints not visible to Kubernetes</li><li>Old deployments laying around consuming unnecessary resources</li><li>Adding costly features without assessing the overall impact</li></ul><p>I have not touched on the last point yet. I started adding <a class=link href=https://pyroscope.io/ target=_blank rel=noopener>Pyroscope</a> to our systems since I simply love monitoring All The Things. The documentation does not go into specifics but emphasizes that it&rsquo;s &ldquo;low overhead&rdquo;. Remember that our budget for CPU usage is actually 40% per node, not 200%. The Pyroscope server itself consumes 10-15% CPU which seems fair. But investigating further the Pyroscope agent also consumes 5-6% CPU per instance. This graph shows the CPU usage of a single Pod before and after turning off Pyroscope profiling.</p><p><img src=/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/pyroscope-agent-cpu.png width=1029 height=271 srcset="/p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/pyroscope-agent-cpu_hu15074112692027608241.png 480w, /p/a-side-quest-in-api-development-observability-kubernetes-and-cloud-with-a-hint-of-database/pyroscope-agent-cpu_hu2516833612973000297.png 1024w" loading=lazy alt=pyroscope-agent-cpu class=gallery-image data-flex-grow=379 data-flex-basis=911px></p><p>5-6% CPU overhead on a highly utilized service is probably worth it. But when the baseline CPU usage is 0% CPU and we have multiple services and deployments in different environments we are suddenly using 40-60% CPU on profiling and less than 1% on actual work!</p><p>The outcome of this is that we need to separate burstable and stable load deployments. Monitoring and supporting systems are usually more stable resource wise while the actual business systems much more variable, and suitable for burst nodes. In practice we add a node pool of non-burst VMs and use NodeAffinity to stick Prometheus, Pyroscope etc to those nodes. Another benefit of this is that the supporting systems needed to troubleshoot problems are now less likely to be impacted by the problem itself, making troubleshooting much easier.</p><p><a id=Conclusion></a></p><h1 id=conclusion>Conclusion</h1><p>This whole adventure only took a few hours but resulted in some specific and immediate performance gains. It also highlighted the weakest links in our application, database and infrastructure architecture.</p></section><footer class=article-footer><section class=article-tags><a href=/tags/kubernetes/>Kubernetes</a>
<a href=/tags/databases/>Databases</a>
<a href=/tags/observability/>Observability</a></section><section class=article-copyright><svg class="icon icon-tabler icon-tabler-copyright" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><path d="M14.5 9a3.5 4 0 100 6"/></svg>
<span>Licensed under CC BY-NC-SA 4.0</span></section><section class=article-lastmod><svg class="icon icon-tabler icon-tabler-clock" width="24" height="24" viewBox="0 0 24 24" stroke-width="2" stroke="currentcolor" fill="none" stroke-linecap="round" stroke-linejoin="round"><path stroke="none" d="M0 0h24v24H0z"/><circle cx="12" cy="12" r="9"/><polyline points="12 7 12 12 15 15"/></svg>
<span>Last updated on Mar 06, 2021 00:00 UTC</span></section></footer></article><aside class=related-content--wrapper><h2 class=section-title>Related content</h2><div class=related-content><div class="flex article-list--tile"><article><a href=/p/kubernetes-sidecar-config-drift/><div class=article-details><h2 class=article-title>Kubernetes Sidecar Config Drift</h2></div></a></article><article class=has-image><a href=/p/end-of-2020-rough-database-landscape/><div class=article-image><img src=/p/end-of-2020-rough-database-landscape/map-nosql.c9e7a90e6cb46866cf2bd4f82b271187_hu2001732389994507380.png width=250 height=150 loading=lazy alt="Featured image of post End of 2020 rough database landscape" data-hash="md5-yeepDmy0aGbPK9T4KycRhw=="></div><div class=article-details><h2 class=article-title>End of 2020 rough database landscape</h2></div></a></article><article class=has-image><a href=/p/mini-post-down-scaling-azure-kubernetes-service-aks/><div class=article-image><img src=/p/mini-post-down-scaling-azure-kubernetes-service-aks/calico-node-cpu.ada85c716b0eb235da02aa0a65aa3303_hu16938543950284632476.png width=250 height=150 loading=lazy alt="Featured image of post Mini-post: Down-scaling Azure Kubernetes Service (AKS)" data-hash="md5-rahccWsOsjXaAqoKZaozAw=="></div><div class=article-details><h2 class=article-title>Mini-post: Down-scaling Azure Kubernetes Service (AKS)</h2></div></a></article><article class=has-image><a href=/p/disk-performance-on-azure-kubernetes-service-aks-part-1-benchmarking/><div class=article-image><img src=/p/disk-performance-on-azure-kubernetes-service-aks-part-1-benchmarking/test1.9cd93c3cd4faad9b6a1de4773ce6d854_hu11291795213924340664.png width=250 height=150 loading=lazy alt="Featured image of post Disk performance on Azure Kubernetes Service (AKS) - Part 1: Benchmarking" data-hash="md5-nNk8PNT6rZtqHeR3PObYVA=="></div><div class=article-details><h2 class=article-title>Disk performance on Azure Kubernetes Service (AKS) - Part 1: Benchmarking</h2></div></a></article><article class=has-image><a href=/p/managed-kubernetes-on-microsoft-azure-english/><div class=article-image><img src=/p/managed-kubernetes-on-microsoft-azure-english/minecraft-k8s.a12cfbcd200722fae02c38e833d8ab36_hu5426546647404073287.png width=250 height=150 loading=lazy alt="Featured image of post Managed Kubernetes on Microsoft Azure (English)" data-hash="md5-oSz7zSAHIvrgLDjoM9irNg=="></div><div class=article-details><h2 class=article-title>Managed Kubernetes on Microsoft Azure (English)</h2></div></a></article></div></div></aside><div class=disqus-container></div><style>.disqus-container{background-color:var(--card-background);border-radius:var(--card-border-radius);box-shadow:var(--shadow-l1);padding:var(--card-padding)}</style><script>window.addEventListener("onColorSchemeChange",e=>{typeof DISQUS=="object"&&DISQUS.reset({reload:!0})})</script><footer class=site-footer><section class=copyright>&copy;
2020 -
2024 blog.stian.omg.lol</section><section class=powerby>Built with <a href=https://gohugo.io/ target=_blank rel=noopener>Hugo</a><br>Theme <b><a href=https://github.com/CaiJimmy/hugo-theme-stack target=_blank rel=noopener data-version=3.29.0>Stack</a></b> designed by <a href=https://jimmycai.com target=_blank rel=noopener>Jimmy</a></section></footer><div class=pswp tabindex=-1 role=dialog aria-hidden=true><div class=pswp__bg></div><div class=pswp__scroll-wrap><div class=pswp__container><div class=pswp__item></div><div class=pswp__item></div><div class=pswp__item></div></div><div class="pswp__ui pswp__ui--hidden"><div class=pswp__top-bar><div class=pswp__counter></div><button class="pswp__button pswp__button--close" title="Close (Esc)"></button>
<button class="pswp__button pswp__button--share" title=Share></button>
<button class="pswp__button pswp__button--fs" title="Toggle fullscreen"></button>
<button class="pswp__button pswp__button--zoom" title="Zoom in/out"></button><div class=pswp__preloader><div class=pswp__preloader__icn><div class=pswp__preloader__cut><div class=pswp__preloader__donut></div></div></div></div></div><div class="pswp__share-modal pswp__share-modal--hidden pswp__single-tap"><div class=pswp__share-tooltip></div></div><button class="pswp__button pswp__button--arrow--left" title="Previous (arrow left)">
</button>
<button class="pswp__button pswp__button--arrow--right" title="Next (arrow right)"></button><div class=pswp__caption><div class=pswp__caption__center></div></div></div></div></div><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.js integrity="sha256-ePwmChbbvXbsO02lbM3HoHbSHTHFAeChekF1xKJdleo=" crossorigin=anonymous defer></script><script src=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe-ui-default.min.js integrity="sha256-UKkzOn/w1mBxRmLLGrSeyB4e1xbrp4xylgAWb3M42pU=" crossorigin=anonymous defer></script><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/default-skin/default-skin.min.css crossorigin=anonymous><link rel=stylesheet href=https://cdn.jsdelivr.net/npm/photoswipe@4.1.3/dist/photoswipe.min.css crossorigin=anonymous></main></div><script src=https://cdn.jsdelivr.net/npm/node-vibrant@3.1.6/dist/vibrant.min.js integrity="sha256-awcR2jno4kI5X0zL8ex0vi2z+KMkF24hUW8WePSA9HM=" crossorigin=anonymous></script><script type=text/javascript src=/ts/main.1e9a3bafd846ced4c345d084b355fb8c7bae75701c338f8a1f8a82c780137826.js defer></script><script>(function(){const e=document.createElement("link");e.href="https://fonts.googleapis.com/css2?family=Lato:wght@300;400;700&display=swap",e.type="text/css",e.rel="stylesheet",document.head.appendChild(e)})()</script></body></html>